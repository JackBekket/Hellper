name: wizard-uncensored-30b
context_size: 2048
f16: false # true to GPU acceleration
cuda: true # true to GPU acceleration
gpu_layers: 10 # this model have max 40 layers, 15-20 is reccomended for half-load at NVIDIA 4060 TiTan (more layers -- more VRAM required), (i guess 0 is no GPU)
parameters:
  model: Wizard-Vicuna-30B-Uncensored.Q4_K_M.gguf
cutstrings:
- "</s>"
template:

  chat: &template |
    Below is an instruction that describes a task. Write a response that appropriately completes the request.
    Instruction: {{.Input}}
    Response:
  # Modify the prompt template here ^^^ as per your requirements
  completion: *template

  #download_files: [https://huggingface.co/TheBloke/Wizard-Vicuna-30B-Uncensored-GGUF/raw/main/Wizard-Vicuna-30B-Uncensored.Q4_K_M.gguf]
