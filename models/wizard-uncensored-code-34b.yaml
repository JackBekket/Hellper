name: wizard-uncensored-code-34b
context_size: 16000
mmap: true
f16: true # true to GPU acceleration
cuda: true # true to GPU acceleration
#gpu_layers: 60 # this model have max 61 layers,  (i guess 0 is no GPU) 
parameters:
  model: huggingface://TheBloke/WizardLM-1.0-Uncensored-CodeLlama-34B-GGUF/wizardlm-1.0-uncensored-codellama-34b.Q4_K_M.gguf
stopwords:
- "HUMAN:"
#- "Human:"
- "<s>"
- "Instruction: "
- "\n\nHuman: "
cutstrings:
- "</s>"
template:
 chat: &template |
   {{.Input}}
 completion: *template
